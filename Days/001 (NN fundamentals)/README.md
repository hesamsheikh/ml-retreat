![alt text](image-1.png)

estimated time: 6.5 h

- In depth-look at the inner workings of a nueral net and the gradient operations.
[The spelled-out intro to neural networks and backpropagation: building micrograd](https://www.youtube.com/watch?v=VMj-3S1tku0&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=1&pp=iAQB)

- some practical PyTorch youtube video [Gradient Calculation With Autograd](https://www.youtube.com/watch?v=DbeIqrwb_dE&list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4&index=3)

- Computational Graph in PyTorch [PyTorch Tutorial 04 - Backpropagation - Theory With Example
](https://www.youtube.com/watch?v=3Kb0QS6z7WA&list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4&index=4)
![alt text](image.png)

- (PyTorch Example code of backprop)[https://www.youtube.com/watch?v=E-I2DNVzQLg&list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4&index=5]

- A look at the classic literature of backpropagation [Learning representations by back-propagating errors.pdf](Days\1\Learning-representations-by-back-propagating-errors.pdf)

- Chapter 6 of the Deep Learning book on Feedforward Networks [Deeplearning Chapter 6](https://www.deeplearningbook.org/contents/mlp.html)